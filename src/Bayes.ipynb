{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/Users/bogdancristianmihaila/Desktop/3rd Semester/ML-project/data/fashion_train.npy\")\n",
    "X = data[:, :-1]  # All rows, first 784 columns\n",
    "y = data[:, -1]   # All rows, last column\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, bin_width=None, use_kde=False):\n",
    "        self.bin_width = bin_width\n",
    "        self.use_kde = use_kde\n",
    "        self.feature_pdfs = {}\n",
    "        self.classes = None\n",
    "\n",
    "    def histogram_pdf(self, data):\n",
    "        counts, bins = np.histogram(data, bins=np.arange(min(data), max(data) + self.bin_width, self.bin_width))\n",
    "        pdf = counts / (len(data) * self.bin_width)\n",
    "        return lambda x: np.interp(x, bins[:-1], pdf, left=0, right=0)\n",
    "\n",
    "    def gaussian_kde_pdf(self, data):\n",
    "        kde = gaussian_kde(data)\n",
    "        return kde.evaluate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        for cls in self.classes:\n",
    "            class_data = X[y == cls]\n",
    "            for i in range(X.shape[1]):\n",
    "                feature = class_data[:, i]\n",
    "                if self.use_kde:\n",
    "                    pdf = self.gaussian_kde_pdf(feature)\n",
    "                else:\n",
    "                    pdf = self.histogram_pdf(feature)\n",
    "                self.feature_pdfs[(cls, i)] = pdf\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            probs = []\n",
    "            for cls in self.classes:\n",
    "                prob = 1\n",
    "                for i, feature_value in enumerate(x):\n",
    "                    prob *= self.feature_pdfs[(cls, i)](feature_value)\n",
    "                probs.append(prob)\n",
    "            predictions.append(self.classes[np.argmax(probs)])\n",
    "        return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Load your data\n",
    "# data, labels = ...\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = NaiveBayesClassifier(bin_width=0.5, use_kde=False)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the classifier\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BACKUP\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, bin_width=1.0, use_kde=False):\n",
    "        self.bin_width = bin_width\n",
    "        self.use_kde = use_kde\n",
    "        self.feature_pdfs = {}\n",
    "        self.classes = None\n",
    "\n",
    "    def histogram_pdf(self, data):\n",
    "        if np.iscomplexobj(data):\n",
    "            raise ValueError(\"Data contains complex numbers, which are not supported for histogram PDF.\")\n",
    "\n",
    "        if self.bin_width is None or self.bin_width <= 0:\n",
    "            raise ValueError(\"Bin width is not properly set.\")\n",
    "\n",
    "        min_data, max_data = np.min(data), np.max(data)\n",
    "        bins = np.arange(min_data, max_data + self.bin_width, self.bin_width)\n",
    "        counts, bins = np.histogram(data, bins=bins)\n",
    "        pdf = counts / (len(data) * self.bin_width)\n",
    "        return lambda x: np.interp(x, bins[:-1], pdf, left=0, right=0)\n",
    "\n",
    "\n",
    "    def gaussian_kde_pdf(self, data):\n",
    "        kde = gaussian_kde(data)\n",
    "        return kde.evaluate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        for cls in self.classes:\n",
    "            class_data = X[y == cls]\n",
    "            for i in range(X.shape[1]):\n",
    "                feature = class_data[:, i]\n",
    "                if self.use_kde:\n",
    "                    pdf = self.gaussian_kde_pdf(feature)\n",
    "                else:\n",
    "                    pdf = self.histogram_pdf(feature)\n",
    "                self.feature_pdfs[(cls, i)] = pdf\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            probs = []\n",
    "            for cls in self.classes:\n",
    "                prob = 1\n",
    "                for i, feature_value in enumerate(x):\n",
    "                    prob *= self.feature_pdfs[(cls, i)](feature_value)\n",
    "                probs.append(prob)\n",
    "            predictions.append(self.classes[np.argmax(probs)])\n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
